{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8663685,"sourceType":"datasetVersion","datasetId":5191199},{"sourceId":8663717,"sourceType":"datasetVersion","datasetId":5191230},{"sourceId":8663826,"sourceType":"datasetVersion","datasetId":5191303},{"sourceId":8663957,"sourceType":"datasetVersion","datasetId":5191400},{"sourceId":8664416,"sourceType":"datasetVersion","datasetId":5191764}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport joblib\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n# Load the CSV file\nprint(\"Loading CSV file...\")\nfile_path = '/kaggle/input/raw-fu/5. Communication_Data_Among_Users (1).csv'\ndata = pd.read_csv(file_path)\nprint(\"CSV file loaded.\")\n\n# Display the first few rows of the dataframe\nprint(\"First few rows of the dataframe:\")\nprint(data.head())\n\n# Extract features and target variable\nprint(\"Extracting features and target variable...\")\nX = data['Message']\ny = data['Label']\n\n# Handle missing values by filling NaNs with an empty string\nX = X.fillna(\"\")\n\n# Handle missing values by filling NaNs with the most frequent value in target\ny = y.fillna(y.mode()[0])\n\n# Convert text data to TF-IDF features\nprint(\"Converting text data to TF-IDF features...\")\nvectorizer = TfidfVectorizer()\nX_tfidf = vectorizer.fit_transform(X)\nprint(\"TF-IDF conversion completed.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T12:11:14.417839Z","iopub.execute_input":"2024-06-11T12:11:14.418298Z","iopub.status.idle":"2024-06-11T12:11:16.960692Z","shell.execute_reply.started":"2024-06-11T12:11:14.418262Z","shell.execute_reply":"2024-06-11T12:11:16.959384Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Loading CSV file...\nCSV file loaded.\nFirst few rows of the dataframe:\n         Date   Time  User1 ID  User2 ID  \\\n0  2021-03-04  10:17       1.0       2.0   \n1  2022-01-24  04:27       1.0       2.0   \n2  2021-02-03  02:19       1.0       2.0   \n3  2021-09-04  08:54       1.0       2.0   \n4  2021-07-21  13:15       1.0       2.0   \n\n                                             Message  Label  \n0  bye bye dear bajaj  i got some better work to ...    1.0  \n1  Haha your so funny you sit on wikipedia all da...    1.0  \n2  My problem is people talking out of their asse...    1.0  \n3                                    Article updated    0.0  \n4  Well arent you phucking special Its easy to ha...    1.0  \nExtracting features and target variable...\nConverting text data to TF-IDF features...\nTF-IDF conversion completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the data into 70% training and 30% testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)\nprint(f\"Training set size: {X_train.shape[0]}\")\nprint(f\"Test set size: {X_test.shape[0]}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T12:11:19.560085Z","iopub.execute_input":"2024-06-11T12:11:19.560544Z","iopub.status.idle":"2024-06-11T12:11:19.582080Z","shell.execute_reply.started":"2024-06-11T12:11:19.560504Z","shell.execute_reply":"2024-06-11T12:11:19.580761Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Training set size: 27823\nTest set size: 11925\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the RandomForest model\nprint(\"Training the Random Forest model...\")\nrf_model = RandomForestClassifier()\nrf_model.fit(X_train, y_train)\nprint(\"Random Forest model trained.\")\n\n# Make predictions with RandomForest model\nprint(\"Making predictions with Random Forest model...\")\ny_pred_rf = rf_model.predict(X_test)\nprint(\"Random Forest model predictions completed.\")\n\n# Evaluate the RandomForest model\nprint(\"Evaluating the Random Forest model...\")\naccuracy_rf = accuracy_score(y_test, y_pred_rf)\nprecision_rf = precision_score(y_test, y_pred_rf, average='binary')\nrecall_rf = recall_score(y_test, y_pred_rf, average='binary')\nf1_rf = f1_score(y_test, y_pred_rf, average='binary')\nconf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n\nprint(f'Random Forest Accuracy: {accuracy_rf}')\nprint(f'Random Forest Precision: {precision_rf}')\nprint(f'Random Forest Recall: {recall_rf}')\nprint(f'Random Forest F1 Score: {f1_rf}')\nprint('Random Forest Confusion Matrix:')\nprint(conf_matrix_rf)\n\n# Define and train the Deep Learning model\nprint(\"Defining the Deep Learning model...\")\ndl_model = Sequential()\ndl_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\ndl_model.add(Dense(32, activation='relu'))\ndl_model.add(Dense(1, activation='sigmoid'))\n\n# Compile the Deep Learning model\nprint(\"Compiling the Deep Learning model...\")\ndl_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Implement early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\n# Train the Deep Learning model\nprint(\"Training the Deep Learning model...\")\ndl_model.fit(X_train.toarray(), y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\nprint(\"Deep Learning model training completed.\")\n\n# Evaluate the Deep Learning model\nprint(\"Evaluating the Deep Learning model...\")\nloss_dl, accuracy_dl = dl_model.evaluate(X_test.toarray(), y_test)\ny_pred_dl = (dl_model.predict(X_test.toarray()) > 0.5).astype(int)  # Convert probabilities to binary class\n\nprecision_dl = precision_score(y_test, y_pred_dl, average='binary')\nrecall_dl = recall_score(y_test, y_pred_dl, average='binary')\nf1_dl = f1_score(y_test, y_pred_dl, average='binary')\nconf_matrix_dl = confusion_matrix(y_test, y_pred_dl)\n\nprint(f'Neural Network Accuracy: {accuracy_dl}')\nprint(f'Neural Network Precision: {precision_dl}')\nprint(f'Neural Network Recall: {recall_dl}')\nprint(f'Neural Network F1 Score: {f1_dl}')\nprint('Neural Network Confusion Matrix:')\nprint(conf_matrix_dl)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T12:11:21.907222Z","iopub.execute_input":"2024-06-11T12:11:21.908269Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training the Random Forest model...\nRandom Forest model trained.\nMaking predictions with Random Forest model...\nRandom Forest model predictions completed.\nEvaluating the Random Forest model...\nRandom Forest Accuracy: 0.8149266247379455\nRandom Forest Precision: 0.8558033451596554\nRandom Forest Recall: 0.6733798604187438\nRandom Forest F1 Score: 0.7537105233790873\nRandom Forest Confusion Matrix:\n[[6341  569]\n [1638 3377]]\nDefining the Deep Learning model...\nCompiling the Deep Learning model...\nTraining the Deep Learning model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the sample test messages CSV file\nprint(\"Loading sample test messages CSV file...\")\ntest_file_path = '/mnt/data/sample_test_messages_20.csv'\ntest_data = pd.read_csv(test_file_path)\nprint(\"Sample test messages loaded.\")\n\n# Ensure the correct column name is used\ncolumn_name = 'Message'  # Adjust this to the correct column name if necessary\n\n# Convert test messages to TF-IDF features\ntest_messages_tfidf = vectorizer.transform(test_data[column_name])\nprint(\"Conversion completed.\")\n\n# Predict using the Random Forest model\ntest_predictions_rf = rf_model.predict(test_messages_tfidf)\nprint(\"Random Forest Predictions:\", test_predictions_rf)\n\n# Predict using the Deep Learning model\ntest_predictions_dl = dl_model.predict(test_messages_tfidf.toarray())\ntest_predictions_dl = (test_predictions_dl > 0.5).astype(int)  # Convert probabilities to binary class\nprint(\"Neural Network Predictions:\", test_predictions_dl)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T12:00:34.804025Z","iopub.execute_input":"2024-06-11T12:00:34.804484Z","iopub.status.idle":"2024-06-11T12:00:35.038654Z","shell.execute_reply.started":"2024-06-11T12:00:34.804441Z","shell.execute_reply":"2024-06-11T12:00:35.037337Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Loading sample test messages CSV file...\nSample test messages loaded.\nConverting test messages to TF-IDF features...\nConversion completed.\nPredicting using the Random Forest model...\nRandom Forest Predictions: [1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0.\n 1. 0. 1. 0. 1. 0.]\nPredicting using the Deep Learning model...\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\nNeural Network Predictions: [[1]\n [0]\n [0]\n [1]\n [0]\n [0]\n [1]\n [0]\n [1]\n [0]\n [1]\n [0]\n [1]\n [0]\n [1]\n [0]\n [0]\n [0]\n [0]\n [1]\n [1]\n [0]\n [0]\n [0]\n [0]\n [0]\n [0]\n [0]\n [1]\n [0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}